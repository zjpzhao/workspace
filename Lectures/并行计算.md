#learning/ParallelComputing

# 3种加速比定律
>**前提**：设$W$、$W_s$和$W_p$分别表示总、串行和并行的计算工作负载，$W=W_s+W_p$，$p$是处理器数量（并行度），串行比例因子$f=W_s/W$，并行比例因子是$1-f$
## 1. Amdahl定律——适用于固定的计算负载
### 加速比
Amdahl定律的加速比$S$表达式及其等价关系如下：
$$\begin{aligned}
S &=\frac{最快的串行算法最坏的运行时间}{并行算法最快的运行时间} \\
& =\frac{W_s+W_p}{W_s+\frac{W_p}{p}} \\
& =\frac{f+(1-f)}{f+\frac{1-f}{p}} \\
& \overset{p\rightarrow \infty }{=}\dfrac{1}{f}
\end{aligned}
$$
### 含义
Amdahl定律适用于固定的计算负载，对于很多实时性要求很高的计算任务，例如一些典型的科学计算，计算负载固定不变，随着处理器数量增加，计算时间将缩短。当处理机数量无限增加时，加速比为$\frac{1}{f}$。
这说明计算负载不变时，加速比最大有个上限，它关于穿行比例因子不是线性关系，而是成反比，也就是说串行比例因子$f$是加速计算的瓶颈。

---

## 2. Gustafson定律——适用于计算负载可变
### 加速比
Gustafson定律的加速比$S$表达式及其等价关系如下：
$$\begin{align}
S &=(W_s+pW_p)/(W_s+W_p) \\
& =(W_s+pW_p)/(W_s+p\cdot W_p/p) \\
& =f+p(1-f) \ ①\\
& =p+f(1-p) \ ②\\
& =p-f(p-1) \ ③
\end{align}$$
### 含义
对于大规模科学计算应用程序，为了提高计算精度就必须增加工作量。相应地为了确保执行时间不变，就必须增加处理及数量。
经过上述推导得到常用的加速比三种相互等价的公式①~③，可见加速比$S$与处理机数目$p$基本上是成线性关系的（任务确定的时候，串行比例因子$f$是一个常数），斜率就是并行比例因子$1-f$。这说明随着处理器数目的增加和工作负载的变化，加速几乎与处理器数成线性增加，串行比例$f$不再是程序的瓶颈。

---
## 3. *Sun & Ni* 定律——适用于计算负载和存储量都可变
### 加速比
假定一个负载的计算量可以由于并行划分而增加$G(p)$倍，（$G(p)$代表负载量增加时，存储容量（需求）也增加p倍），Sun 和 Ni 定律的加速比$S$表达式及其等价关系如下：
$$\begin{align}
S &=\frac{W_s+G(p)W_p}{W_s+G(p)W_p/p} \\
& =\frac{f+G(p)(1-f)}{f+G(p)(1-f)/p}
\end{align}$$
### 含义
在Amdahl和Gustafson定理中都是认为处理机数和存储容量是不受限制地可增加的，但是可能有一些大的求解问题可能要受到存储容量的限制。前两个定律并没有考虑到存储容量的变化，也就是说要求规划负载，提供更高的加速比、更高的精度和更好的资源利用率。
在上式基础上进行讨论并继续推导：
- 当$G(p)=1$时，存储量增加p倍，负载量增加仅为1很小（负载量相当于不变）。代入上式得到下式，相当于Amdahl定律。
$$
	S = \frac{f+(1-f)}{f+(1-f)/p}
$$
- 当$G(p)=p$时，即存储量增加p倍，负载也增加。代入上式得到下式，相当于Gustafson定律。
$$
S=f+p(1-f)
$$
该定律的工作负载和执行时间都变化，处理能力（能处理的工作负载）随着处理器数目的增加而增加；执行时间随着处理器数目的增加而增加。

---

# 三种等效率定律
## 基于ISO-efficiency 等效度量标准
等效度量标准是研究如何维持并行系统的等效性
### 表达式推导
设$T_1$是一个给定问题在一台机器上串行执行的时间（例如$W$），$T_p$是在$p$台处理机上并行执行的时间，$T_0$是额外开销，则有
$$
T_1+T_0 =p \times T_p \tag{1}
$$

加速比$S$表达式如下：
$$\begin{align}
S & = \frac{T_e}{T_p} =\frac{T_1}{(T_1+T_0)/p}=\frac{p}{1+\frac{T_0}{W}} \tag{2}
\end{align}$$

效率$E$表达式如下
$$\begin{align}
E & =\frac{S}{p} =\frac{1}{1+\frac{T_0}{T_1}}=\frac{1}{1+\frac{T_0}{W}} \tag{3}
\end{align}$$
### 含义
$(1)$式的含义：问题规模$W$可定义为由最佳串行算法完成的计算量，也称为工作负载或工作量，即$T_1=W$，这里的额外开销是并行模式下由通信、算法、交叉等待等引起的开销，串行执行时间与并行执行的额外开销时间之和等于并行执行时间之和，这里考虑的是绝对加速（所有机器的累加时间）。
$(2)(3)$式的含义：如果问题规模$W$不变，那么随着处理及数量$p$的增加，额外开销$T_0$也会增加，从而引起效率下降。为了保证$E$不变，就要保证$\frac{T_0}{T_1}$不变，这就要求增加处理机数$p$的同时，增加问题规模$W$，即$T_1$。依照此定义的函数称为等效率函数。这里的加速比考虑的也是对绝对时间的加速（所有机器的累加时间），而效率定义的意义在于将整体加速比分摊到每一个处理器上得到的加速比，体现单机的加速效率。

### 优缺点
- 优点：等效率函数是一种用分析方法处理工作负载增长率与处理机增长率之间关系的有用的工具，可用简单的、可定量计算的、少量的参数就能计算出等效率函数，并由其复杂性可指出算法的可扩放程度。
	- 如果$W$与$p$呈线性关系，则系统是可扩放的
	- 如果$W$与$p$呈指数关系，则系统是不可扩放的
- 缺点：对共享存储器结构的机器难以计算等效率函数值，因为分时共享开销变化影响计算性能。

---

### ISO-speed 等速度量标准
### 表达式推导
等速度标准是在机器规模由p增加到p',问题规模由W增加到W'时，维持平均速度不变，此时的可扩放的速度度量标准函数为：

![](https://zjpimage.oss-cn-qingdao.aliyuncs.com/20220518232537.png)
当平均速度严格不变时：
![](https://zjpimage.oss-cn-qingdao.aliyuncs.com/20220518232647.png)
当p=1时:
![](https://zjpimage.oss-cn-qingdao.aliyuncs.com/20220518233023.png)

### 含义
如果速度能与处理机的数目的增加而线性增加，即意味着平均速度不变，则说明此系统具有很好的扩放性。

### 优缺点
优点：
- 使用机器性能速度指标这一明确的物理量来度量可扩放性是比较直观的（速度常被用来测量浮点运算）速度是由工作负载W和执行时间T决定的，而W反映了应用程序的性质，T反映了结构和程序效率的影响；速度在各种结构的机器之间具有可比性；执行时间包含了计算和延迟这两个主要的时间量；速度是比较容易测量的。（如何使用浮点操作数量）
缺点：某些非浮点运算可造成性能的变化；延迟虽包含在执行时间中，但它明确地定义为W的函数。

---

### Aerage Lantency 平均延迟度量标准
### 表达式推导
效率不变前提下，用平均延迟来标志处理机数p和工作量W之间的增量关系。平均延迟时间定义为一个处理机完成分配给他的任务所需要的平均时间开销。包括运行时的延迟Li，启动时间及停止时间。因此第i个处理器Pi的总的延迟时间为：Li  +  启动时间  +停止时间
系统的平均延迟时间为：
![](https://zjpimage.oss-cn-qingdao.aliyuncs.com/20220518233554.png)
由于：![](https://zjpimage.oss-cn-qingdao.aliyuncs.com/20220518233653.png)
所以
![](https://zjpimage.oss-cn-qingdao.aliyuncs.com/20220518233700.png)
令L(W,p)表示在P个处理器上求解工作量为W问题的平均延迟，L(W,p')表示在p'个处理器上求解工作量为W'问题的平均延迟，则定义平均延迟可扩放性度量标准为：
![](https://zjpimage.oss-cn-qingdao.aliyuncs.com/20220518232740.png)
### 优缺点
优点
平均延迟是一个实验性标准，可精确地评估低档系统
缺点
需要特殊的硬件和系统软件进行实验测试

### 等价关系
等效标准与等速标准是等价的；平均延迟标准可以源自等速标准；三者均是等价的。

---

# 并行算法
## 算法指标
运行时间t(n)，处理机数(复杂度)p(n)，
并行算法的运行时间$t(n)$与其所需处理器数量$p(n)$的乘积，即$T(n)=t(n)*p(n)$

 ## Brent定理（W-work-step）
令W(n)是一并行算法A在运行时间T(n)内所执行的运算数量，则A使用p台处理器可在时间内完成。

