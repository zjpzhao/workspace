#learning/ParallelComputing

# 3种加速比定律
>**前提**：设$W$、$W_s$和$W_p$分别表示总、串行和并行的计算工作负载，$W=W_s+W_p$，$p$是处理器数量（并行度），串行比例因子$f=W_s/W$，并行比例因子是$1-f$
## 1. Amdahl定律——适用于固定的计算负载
### 加速比
Amdahl定律的加速比$S$表达式及其等价关系如下：
$$\begin{aligned}
S &=\frac{最快的串行算法最坏的运行时间}{并行算法最快的运行时间} \\
& =\frac{W_s+W_p}{W_s+\frac{W_p}{p}} \\
& =\frac{f+(1-f)}{f+\frac{1-f}{p}} \\
& \overset{p\rightarrow \infty }{=}\dfrac{1}{f}
\end{aligned}
$$
### 含义
Amdahl定律适用于固定的计算负载，对于很多实时性要求很高的计算任务，例如一些典型的科学计算，计算负载固定不变，随着处理器数量增加，计算时间将缩短。当处理机数量无限增加时，加速比为$\frac{1}{f}$。
这说明计算负载不变时，加速比最大有个上限，它关于穿行比例因子不是线性关系，而是成反比，也就是说串行比例因子$f$是加速计算的瓶颈。

---

## 2. Gustafson定律——适用于计算负载可变
### 加速比
Gustafson定律的加速比$S$表达式及其等价关系如下：
$$\begin{align}
S &=(W_s+pW_p)/(W_s+W_p) \\
& =(W_s+pW_p)/(W_s+p\cdot W_p/p) \\
& =f+p(1-f) \ ①\\
& =p+f(1-p) \ ②\\
& =p-f(p-1) \ ③
\end{align}$$
### 含义
对于大规模科学计算应用程序，为了提高计算精度就必须增加工作量。相应地为了确保执行时间不变，就必须增加处理及数量。
经过上述推导得到常用的加速比三种相互等价的公式①~③，可见加速比$S$与处理机数目$p$基本上是成线性关系的（任务确定的时候，串行比例因子$f$是一个常数），斜率就是并行比例因子$1-f$。这说明随着处理器数目的增加和工作负载的变化，加速几乎与处理器数成线性增加，串行比例$f$不再是程序的瓶颈。

---
## 3. *Sun & Ni* 定律——适用于计算负载和存储量都可变
### 加速比
假定一个负载的计算量可以由于并行划分而增加$G(p)$倍，（$G(p)$代表负载量增加时，存储容量（需求）也增加p倍），Sun 和 Ni 定律的加速比$S$表达式及其等价关系如下：
$$\begin{align}
S &=\frac{W_s+G(p)W_p}{W_s+G(p)W_p/p} \\
& =\frac{f+G(p)(1-f)}{f+G(p)(1-f)/p}
\end{align}$$
### 含义
在Amdahl和Gustafson定理中都是认为处理机数和存储容量是不受限制地可增加的，但是可能有一些大的求解问题可能要受到存储容量的限制。前两个定律并没有考虑到存储容量的变化，也就是说要求规划负载，提供更高的加速比、更高的精度和更好的资源利用率。
在上式基础上进行讨论并继续推导：
- 当$G(p)=1$时，存储量增加p倍，负载量增加仅为1很小（负载量相当于不变）。代入上式得到下式，相当于Amdahl定律。
$$
	S = \frac{f+(1-f)}{f+(1-f)/p}
$$
- 当$G(p)=p$时，即存储量增加p倍，负载也增加。代入上式得到下式，相当于Gustafson定律。
$$
S=f+p(1-f)
$$
该定律的工作负载和执行时间都变化，处理能力（能处理的工作负载）随着处理器数目的增加而增加；执行时间随着处理器数目的增加而增加。