# 第一天

感谢你完成第一天的学习。我们完成了：

1.    

基于Arm的Jetson开发环境介绍，Arm Linux系统简介（1.1理论课+实验课）

介绍我们的实验平台，介绍Linux编译的基本技巧，介绍基本的开发环境

实验课：Makefile 编写规范

2.    

GPU架构及异构计算（1.2）

  介绍GPU架构以及异构计算的基本原理

  介绍GPU硬件平台

  介绍基于Arm的嵌入式平台GPU架构和编程模型之间的关系，介绍Grace CPU相关

  最新的GPU应用领域，GPU在现代计算机科学中的通用性

3.    

CUDA编程模型---初识CUDA（1.3+1.4实验课）

  CUDA程序的编译

  GPU线程的调用

  GPU和CPU的通讯

  使用多个线程的核函数

  使用线程索引

  多维网络

  网格与线程块

  利用NVProf查看程序执行情况

  实验课内容：编写程序HelloCUDA，并且利用NVCC编译。编写VectorAdd多线程程序，和多维网络线程程序，并用nvprof来测试不同设置情况下运行速

请完成今天的打卡作业！

# 第二天

Day 1 学习要点总结：

1. __device__ 的返回类型可以不是void？

--可以的。但这种情况下，执行的效果可能需要其他方式返回了。（例如通过一个参数int \*p, 然后写入p指向的空间），

2.一般返回值都通过指针参数返回比较好？

--都行，常见的习惯是标量值，可以直接作为返回值，每个线程超过1个值（例如需要返回10个float），则建议用指针。

 3. 和CPU上只能同时执行有限数量（常见的例如8核16个超线程的CPU）的十几个、几十个。GPU上能同时执行海量的线程数量，例如几十万、上百万。可以有效的发挥GPU设备的能力。而如何有效的管理这么大数量的线程，则需要"线程组织形式", 可以有效的管理、执行问题，避免混乱。

 4. 来自Fortran同学注意了，我们的GPU上的CUDA C语言，采用的是下标从0开始，而不是1.

5. 学校：1个grid /年级：1个block/班：1个block/你：1个线程

6. 指定超过ＳＭ中ｃｏｒｅ数量的话会怎样？无问题的。你可以理解成每个SM都是海量超线程的。例如我们本次例子的Jetson设备，1个SM只有128个SP，却可以同时执行2048个线程（你可以理解成16倍超线程）。再多也是可以的，用其他方式继续调度

7. 线程数目可以远大于物理core数目

 8. 1个block在一个sm里面执行，sm是什么？

--一般情况下，可以直接将GPU的SM理解成CPU的一个物理核心. 按SM划分有好多好处。例如一个GPU可以简单的通过横向扩充SM，即可扩大规模。例如1个block的线程限定给1个SM，可以让1个block的线程在SM内部高效的执行数据交换/交流/同步之类的。

9. 写cuda程序的时候能申请的最大线程数不是无限的, 最大的线程数量：1024\*(2^31-1)\*65535\*65535

 10. 一个block有多少个线程是调用的时候自己指定的？而不是固定的？是自己（你）定的。

11. 如果两个进程运行，调用的函数都同时使用同一个blockid和threadid，会不会有冲突的？

--不会。依然各自是各自的线程（虽然两次启动线程的编号有重复的）。

 12. 不能直接将一次kernel启动理解成1个CPU上的process的。两回事。你理解成“一次能开辟很多线程的函数调用较好”。

13. 如果cuda申请的thread不足了，调用的函数会怎么样？？就是报错如何处理？

--如果你指定了超多的启动规模，超出了你卡的能力，会报告“无效启动配置”。

14. cudaDeviceSynchronize();是同步哪个步骤呢，是不同block的计算结果么？

--CPU上的调用者等待GPU上的之前的所有进行中的异步任务完成。和GPU上的blocks之间互相同步（那个叫全局同步）无关。

Day 2 我们将学习：

1.    

CUDA编程模型---CUDA存储单元的使用与错误检测（2.1+2.2实验课）

  设备初始化

  GPU的存储单元

  GPU存储单元的分配与释放

  数据的传输

  数据与线程之间的对应关系

  CUDA应用程序运行时的错误检测

  CUDA中的事件

  利用事件进行计时

  实验课内容：编写MatrixMul程序，体验线程和数据的对应关系

  留课后作业

2.    

多种CUDA存储单元详解（2.3）

  CUDA中的存储单元种类

  CUDA中的各种存储单元的使用方法

  CUDA中的各种存储单元的适用条件

3.    

利用共享存储单元优化应用（2.4实验课）

  共享存储单元详解

  共享内存的Bank conflict

  利用共享存储单元进行矩阵转置和矩阵乘积

  实验课内容：编写Shared Memory优化过的矩阵乘法

介绍shared memory原理，介绍利用shared memory 优化的多种案例

  矩阵转置

# 第三天

Day 2 课程总结：

1.   block和block中的线程，只有先上到SM（流多处理器）内部，才可能开始执行。因此Ken老师强调说，每个block使用的资源少点，则1个SM上可能有更多的blocks（和其中的线程）在被调度执行中。注意这里的最后一句的活动warps. 在很多NV的文档场合，active和resident warps是混用的（都代表了驻留的warps。前者常见于nsight文档，后者常见于CUDA的文档），都是指上到了SM上的block中的（warps）。

2.   注意像是c = a \* 1.23456f + b; 这里的1.23456f是所有线程都一致的编译时刻常数，编译器会自动收集这种，并全自动的放入constant cache. 不需要手工放（例如通过幻灯片中的__constant__ 和 cudaMemcpyToSymbol）

3.   2D或者3D存储上的“空间临近性".这点和普通的cache（线性地址，例如连续的64B之类的）不同。texture cache模拟的“空间上的局部性"缓冲。

4.    注意在GPU上warp整体在并行，不是1个线程各自为战。在GPU编程中，总是以warp的角度去看事情的（32个线程）。所以是否真的按行，得从warp的角度看。

5.     shared memory：（1）当成一个局部的小高速的交换数据的小Scratch buffer用。（2）当成一个服务多次重复数据访问的，手工管理的cache来用。（3）将直接访问global memory不合适的pattern，通过shared memory中转后，变成合适的（哪怕此时并没有显著的多次重复使用）。

6.     很多GPU设备上，L1 cache和shared memory共享物理的存储单元（但我们本次课程的平台(Jetson)上不是。和L1 cache互相独立）。

7.     shared memory有多个独立的bank，每个bank都可以独立工作。但不能同一周期内，有2个线程使用同1个bank（的不同深度的内容）。shared memory不使用虚拟内存（直接使用物理地址访问）

8.    当warp中的32个线程无冲突的访问多个banks的时候，这些banks可以同时工作，并行给出数据，性能很好。

9.      为啥不是只读取完整的一行到share memory？ 而要读tile 行，然后截取列？

--我们的shared memory容量有限，无法直接容纳一个16\*N（对于MxN \* N\*K的两个矩阵来说），那么巨大的公用共享空间。所以每次用一个小的（例如,16x16的小shared memory，然后反复重用这个小的，用完的数据就扔掉，再滑动）。

10.  请问texture memory在这里是不是也适用呢？

--理论各种普通cache都可以考虑用，但是实际上shared的表现往往最好。所以本例使用shared（主要是超低延迟，行列转置之类的免费）这里比较好。

11.  shared memory容量最大值可以确定或者获取到吗？还是每次都保险用16x16的小shared memory？

--可以获取到，目前所有你能买到的卡都至少48KB。但是使用16x16还有其他的原因。主要是尽量使用方块容易理解。而下一级的方块就是32x32了（最大1024），所以用16x16较好。而用8x8的方块又太小。

12.  怎么判断有没有发生bank conflict？

--每行warp访问shared memory，你如果找不出来任意2个线程，能访问同1个bank的不同深度，那就没有。（或者用人话说，对于4B的元素构成的数组，1D化后的元素下标，你找不到2个线程能正好相邻32的倍数，那就没有），注意这是对每次warp访存shared来说的。多次之间无干扰。

13.  做shared memory进行矩阵乘法的例子，同学们不要迷惑了。block中的线程在集体合力读取内容到shared memory中的时候，是以block整体的访存的（坐标）的角度出发的。而当它们完成了写入，执行完了__syncthreads()后，再次就是各自为战负责1个点的坐标了（目标矩阵里的坐标）。这里面的坐标的身份有变化，大家不要迷惑了！

14.   学会了这个走shared memory的矩阵乘法，你会学会：（1）如何使用一种高速存储单元。（2）如果以warp整体的角度访存global的思考。（3）如何同一个kernel的代码中，前后片段中的每个线程，有不同的身份/工作。

15.     在我们申请的block中所有线程已经确定知道要去求P矩阵中的那个值的时候，它们的by已经确定了，那是线程自身的属性，不会变得。我们只是帮助线程去找它所需要的数据。

感谢您完成Day3的课程。我们今天将要学习了：

1.    

CUDA编程模型---原子操作（3.1理论+3.2实验）

  CUDA中的原子操作

  原子操作的适用场景

  利用原子操作优化程序

2.    

基于ARM平台的Jetson NANO存储单元调用（3.3+3.4实验课）

  基于ARM平台的Jetson nano的存储单元特点

  统一内存的基本概念

  如何更有效的利用Jetson的存储单元

  实验课内容：编写MatrixMul程序，体验统一内存的使用方法

介绍基于Jetson平台的共享存储单元的特点，介绍Jetson平台SoC DRAM memory的应用

请完成今天的打卡作业

# 第四天

感谢您完成今天的课程。我们学习了：

1.    

CUDA stream（4.1+4.2实验课）

  CUDA流的基本概念

  默认流与非默认流

  利用CUDA流重叠计算和数据传输

  实验课内容：体验利用流来减少运行时间

介绍CUDA stream，介绍利用Stream分割处理的加速方案，介绍利用stream处理超大数据的加速方案

2.    

CUDA加速库介绍：cuBLAS，cuFFT（4.3+4.4实验课）

  cuBLAS介绍

  cuFFT介绍

  利用cuFFT和cuBLAS来实现相关应用案例

请完成今天的打卡作业

# 第五天
填写调查问卷，完成打卡